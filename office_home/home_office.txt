Loading dataset 'oh-65cls'
Train dataset length: 8804
Valid dataset length: 500
Test dataset length: 1900
Perturbations dataset length: 1957

Training 
{'ensemble_size': 5, 'batch_size_train': 128, 'batch_size_eval': 512, 'seed': 0, 'device': device(type='cuda', index=0), 'epochs': 600, 'lr': 0.001, 'l2_reg': 0.0001, 'scheduler': 'none', 'opt': 'sgd', 'eval_freq': 1000, 'ckpt_freq': 1, 'results_base_folder': './exps', 'no_diversity': True, 'dbat_loss_type': 'v1', 'perturb_type': 'ood_is_test', 'alpha': 0.0, 'model': 'resnet18', 'dataset': 'oh-65cls'}

[m1] 0:0 [train] erm-loss: 4.623, adv-loss: 0.000 [valid] acc: 0.016 
[m1] 14:1000 [train] erm-loss: 0.271, adv-loss: 0.000 [valid] acc: 0.508 
[m1] 28:2000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.510 
[m1] 43:3000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 57:4000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.512 
[m1] 72:5000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 86:6000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 101:7000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 115:8000 [train] erm-loss: 0.030, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 130:9000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.528 
[m1] 144:10000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 159:11000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 173:12000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.528 
[m1] 188:13000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.512 
[m1] 202:14000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 217:15000 [train] erm-loss: 0.032, adv-loss: 0.000 [valid] acc: 0.516 
[m1] 231:16000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 246:17000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.528 
[m1] 260:18000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 275:19000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 289:20000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 304:21000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 318:22000 [train] erm-loss: 0.035, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 333:23000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 347:24000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.516 
[m1] 362:25000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 376:26000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 391:27000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.528 
[m1] 405:28000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 420:29000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 434:30000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 449:31000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 463:32000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.538 
[m1] 478:33000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 492:34000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 507:35000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 521:36000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.528 
[m1] 536:37000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 550:38000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.516 
[m1] 565:39000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 579:40000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 594:41000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.530 
[m2] 0:0 [train] erm-loss: 4.600, adv-loss: 0.000 [valid] acc: 0.012 
[m2] 14:1000 [train] erm-loss: 0.164, adv-loss: 0.000 [valid] acc: 0.516 
[m2] 28:2000 [train] erm-loss: 0.078, adv-loss: 0.000 [valid] acc: 0.526 
[m2] 43:3000 [train] erm-loss: 0.037, adv-loss: 0.000 [valid] acc: 0.528 
[m2] 57:4000 [train] erm-loss: 0.077, adv-loss: 0.000 [valid] acc: 0.538 
[m2] 72:5000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 86:6000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 101:7000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.526 
[m2] 115:8000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.530 
[m2] 130:9000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 144:10000 [train] erm-loss: 0.003, adv-loss: 0.000 [valid] acc: 0.526 
[m2] 159:11000 [train] erm-loss: 0.003, adv-loss: 0.000 [valid] acc: 0.528 
[m2] 173:12000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.532 
[m2] 188:13000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 202:14000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 217:15000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 231:16000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.530 
[m2] 246:17000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 260:18000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.528 
[m2] 275:19000 [train] erm-loss: 0.045, adv-loss: 0.000 [valid] acc: 0.532 
[m2] 289:20000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.532 
[m2] 304:21000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 318:22000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.532 
[m2] 333:23000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.530 
[m2] 347:24000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 362:25000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 376:26000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 391:27000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.528 
[m2] 405:28000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.538 
[m2] 420:29000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 434:30000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.526 
[m2] 449:31000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.528 
[m2] 463:32000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 478:33000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.530 
[m2] 492:34000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.530 
[m2] 507:35000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.520 
[m2] 521:36000 [train] erm-loss: 0.035, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 536:37000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 550:38000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 565:39000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 579:40000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 594:41000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 0:0 [train] erm-loss: 4.524, adv-loss: 0.000 [valid] acc: 0.008 
[m3] 14:1000 [train] erm-loss: 0.183, adv-loss: 0.000 [valid] acc: 0.520 
[m3] 28:2000 [train] erm-loss: 0.048, adv-loss: 0.000 [valid] acc: 0.536 
[m3] 43:3000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.528 
[m3] 57:4000 [train] erm-loss: 0.070, adv-loss: 0.000 [valid] acc: 0.522 
[m3] 72:5000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 86:6000 [train] erm-loss: 0.033, adv-loss: 0.000 [valid] acc: 0.532 
[m3] 101:7000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 115:8000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.528 
[m3] 130:9000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.536 
[m3] 144:10000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.542 
[m3] 159:11000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 173:12000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.536 
[m3] 188:13000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.540 
[m3] 202:14000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.544 
[m3] 217:15000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.542 
[m3] 231:16000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.538 
[m3] 246:17000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.544 
[m3] 260:18000 [train] erm-loss: 0.046, adv-loss: 0.000 [valid] acc: 0.548 
[m3] 275:19000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.540 
[m3] 289:20000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.544 
[m3] 304:21000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.556 
[m3] 318:22000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.540 
[m3] 333:23000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.548 
[m3] 347:24000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.548 
[m3] 362:25000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.554 
[m3] 376:26000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.550 
[m3] 391:27000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.538 
[m3] 405:28000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.544 
[m3] 420:29000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.546 
[m3] 434:30000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.536 
[m3] 449:31000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.542 
[m3] 463:32000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.536 
[m3] 478:33000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.542 
[m3] 492:34000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.552 
[m3] 507:35000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.542 
[m3] 521:36000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.550 
[m3] 536:37000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.550 
[m3] 550:38000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.544 
[m3] 565:39000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.550 
[m3] 579:40000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.548 
[m3] 594:41000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.546 
[m4] 0:0 [train] erm-loss: 4.612, adv-loss: 0.000 [valid] acc: 0.010 
[m4] 14:1000 [train] erm-loss: 0.135, adv-loss: 0.000 [valid] acc: 0.518 
[m4] 28:2000 [train] erm-loss: 0.075, adv-loss: 0.000 [valid] acc: 0.546 
[m4] 43:3000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.540 
[m4] 57:4000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 72:5000 [train] erm-loss: 0.043, adv-loss: 0.000 [valid] acc: 0.542 
[m4] 86:6000 [train] erm-loss: 0.063, adv-loss: 0.000 [valid] acc: 0.542 
[m4] 101:7000 [train] erm-loss: 0.041, adv-loss: 0.000 [valid] acc: 0.534 
[m4] 115:8000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.532 
[m4] 130:9000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.534 
[m4] 144:10000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 159:11000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.540 
[m4] 173:12000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.536 
[m4] 188:13000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.548 
[m4] 202:14000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 217:15000 [train] erm-loss: 0.035, adv-loss: 0.000 [valid] acc: 0.546 
[m4] 231:16000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 246:17000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.532 
[m4] 260:18000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.534 
[m4] 275:19000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.532 
[m4] 289:20000 [train] erm-loss: 0.030, adv-loss: 0.000 [valid] acc: 0.536 
[m4] 304:21000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.540 
[m4] 318:22000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 333:23000 [train] erm-loss: 0.004, adv-loss: 0.000 [valid] acc: 0.534 
[m4] 347:24000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.526 
[m4] 362:25000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.526 
[m4] 376:26000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.532 
[m4] 391:27000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.536 
[m4] 405:28000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.530 
[m4] 420:29000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.548 
[m4] 434:30000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.544 
[m4] 449:31000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.534 
[m4] 463:32000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.532 
[m4] 478:33000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.540 
[m4] 492:34000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 507:35000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.536 
[m4] 521:36000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.540 
[m4] 536:37000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.548 
[m4] 550:38000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.540 
[m4] 565:39000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.542 
[m4] 579:40000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.538 
[m4] 594:41000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.538 
[m5] 0:0 [train] erm-loss: 4.466, adv-loss: 0.000 [valid] acc: 0.038 
[m5] 14:1000 [train] erm-loss: 0.158, adv-loss: 0.000 [valid] acc: 0.536 
[m5] 28:2000 [train] erm-loss: 0.057, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 43:3000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.562 
[m5] 57:4000 [train] erm-loss: 0.056, adv-loss: 0.000 [valid] acc: 0.558 
[m5] 72:5000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.548 
[m5] 86:6000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 101:7000 [train] erm-loss: 0.031, adv-loss: 0.000 [valid] acc: 0.562 
[m5] 115:8000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.550 
[m5] 130:9000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.558 
[m5] 144:10000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.542 
[m5] 159:11000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.554 
[m5] 173:12000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 188:13000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.560 
[m5] 202:14000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.550 
[m5] 217:15000 [train] erm-loss: 0.051, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 231:16000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.550 
[m5] 246:17000 [train] erm-loss: 0.046, adv-loss: 0.000 [valid] acc: 0.552 
[m5] 260:18000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.550 
[m5] 275:19000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.552 
[m5] 289:20000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.554 
[m5] 304:21000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.562 
[m5] 318:22000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.564 
[m5] 333:23000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.550 
[m5] 347:24000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.544 
[m5] 362:25000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.554 
[m5] 376:26000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 391:27000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.554 
[m5] 405:28000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.560 
[m5] 420:29000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.548 
[m5] 434:30000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.546 
[m5] 449:31000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 463:32000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 478:33000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.552 
[m5] 492:34000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.558 
[m5] 507:35000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.558 
[m5] 521:36000 [train] erm-loss: 0.036, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 536:37000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 550:38000 [train] erm-loss: 0.036, adv-loss: 0.000 [valid] acc: 0.554 
[m5] 565:39000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.556 
[m5] 579:40000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.564 
[m5] 594:41000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.556 
[test m1] test-acc: 0.499
[test m2] test-acc: 0.502
[test m3] test-acc: 0.499
[test m4] test-acc: 0.488
[test m5] test-acc: 0.514
[test (last iterates ensemble)] test-acc: 0.538
[test ensemble given size] 0.499, 0.517, 0.529, 0.533, 0.538
Loading dataset 'oh-65cls'
Train dataset length: 8804
Valid dataset length: 500
Test dataset length: 1900
Perturbations dataset length: 1957

Training 
{'ensemble_size': 5, 'batch_size_train': 128, 'batch_size_eval': 512, 'seed': 0, 'device': device(type='cuda', index=0), 'epochs': 600, 'lr': 0.001, 'l2_reg': 0.0001, 'scheduler': 'none', 'opt': 'sgd', 'eval_freq': 1000, 'ckpt_freq': 1, 'results_base_folder': './exps', 'no_diversity': False, 'dbat_loss_type': 'v1', 'perturb_type': 'ood_is_test', 'alpha': 1e-05, 'model': 'resnet18', 'dataset': 'oh-65cls'}

[m1] 0:0 [train] erm-loss: 4.623, adv-loss: 0.000 [valid] acc: 0.016 
[m1] 14:1000 [train] erm-loss: 0.268, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 28:2000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.510 
[m1] 43:3000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 57:4000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 72:5000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 86:6000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 101:7000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 115:8000 [train] erm-loss: 0.030, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 130:9000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.530 
[m1] 144:10000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 159:11000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 173:12000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 188:13000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 202:14000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 217:15000 [train] erm-loss: 0.032, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 231:16000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 246:17000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 260:18000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 275:19000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 289:20000 [train] erm-loss: 0.037, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 304:21000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.516 
[m1] 318:22000 [train] erm-loss: 0.036, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 333:23000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 347:24000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 362:25000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 376:26000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 391:27000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.516 
[m1] 405:28000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 420:29000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 434:30000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 449:31000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 463:32000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.528 
[m1] 478:33000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.518 
[m1] 492:34000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 507:35000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 521:36000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.516 
[m1] 536:37000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 550:38000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.510 
[m1] 565:39000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.514 
[m1] 579:40000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 594:41000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.514 
[m2] 0:0 [train] erm-loss: 4.600, adv-loss: 0.462 [valid] acc: 0.014 
[m2] 14:1000 [train] erm-loss: 0.165, adv-loss: 1.337 [valid] acc: 0.516 
[m2] 28:2000 [train] erm-loss: 0.077, adv-loss: 1.541 [valid] acc: 0.530 
[m2] 43:3000 [train] erm-loss: 0.038, adv-loss: 1.523 [valid] acc: 0.530 
[m2] 57:4000 [train] erm-loss: 0.074, adv-loss: 1.552 [valid] acc: 0.536 
[m2] 72:5000 [train] erm-loss: 0.014, adv-loss: 1.907 [valid] acc: 0.540 
[m2] 86:6000 [train] erm-loss: 0.024, adv-loss: 2.222 [valid] acc: 0.544 
[m2] 101:7000 [train] erm-loss: 0.011, adv-loss: 2.002 [valid] acc: 0.548 
[m2] 115:8000 [train] erm-loss: 0.017, adv-loss: 1.727 [valid] acc: 0.550 
[m2] 130:9000 [train] erm-loss: 0.015, adv-loss: 1.831 [valid] acc: 0.548 
[m2] 144:10000 [train] erm-loss: 0.003, adv-loss: 1.900 [valid] acc: 0.552 
[m2] 159:11000 [train] erm-loss: 0.003, adv-loss: 1.676 [valid] acc: 0.550 
[m2] 173:12000 [train] erm-loss: 0.029, adv-loss: 2.509 [valid] acc: 0.544 
[m2] 188:13000 [train] erm-loss: 0.019, adv-loss: 2.055 [valid] acc: 0.544 
[m2] 202:14000 [train] erm-loss: 0.006, adv-loss: 2.306 [valid] acc: 0.546 
[m2] 217:15000 [train] erm-loss: 0.013, adv-loss: 1.842 [valid] acc: 0.546 
[m2] 231:16000 [train] erm-loss: 0.019, adv-loss: 2.182 [valid] acc: 0.554 
[m2] 246:17000 [train] erm-loss: 0.014, adv-loss: 2.144 [valid] acc: 0.552 
[m2] 260:18000 [train] erm-loss: 0.002, adv-loss: 1.735 [valid] acc: 0.546 
[m2] 275:19000 [train] erm-loss: 0.044, adv-loss: 2.338 [valid] acc: 0.550 
[m2] 289:20000 [train] erm-loss: 0.015, adv-loss: 2.210 [valid] acc: 0.552 
[m2] 304:21000 [train] erm-loss: 0.011, adv-loss: 2.181 [valid] acc: 0.550 
[m2] 318:22000 [train] erm-loss: 0.019, adv-loss: 2.080 [valid] acc: 0.546 
[m2] 333:23000 [train] erm-loss: 0.001, adv-loss: 2.046 [valid] acc: 0.546 
[m2] 347:24000 [train] erm-loss: 0.001, adv-loss: 1.954 [valid] acc: 0.542 
[m2] 362:25000 [train] erm-loss: 0.019, adv-loss: 2.049 [valid] acc: 0.540 
[m2] 376:26000 [train] erm-loss: 0.001, adv-loss: 2.067 [valid] acc: 0.556 
[m2] 391:27000 [train] erm-loss: 0.001, adv-loss: 2.115 [valid] acc: 0.546 
[m2] 405:28000 [train] erm-loss: 0.001, adv-loss: 2.141 [valid] acc: 0.558 
[m2] 420:29000 [train] erm-loss: 0.005, adv-loss: 1.885 [valid] acc: 0.550 
[m2] 434:30000 [train] erm-loss: 0.001, adv-loss: 2.233 [valid] acc: 0.540 
[m2] 449:31000 [train] erm-loss: 0.022, adv-loss: 2.480 [valid] acc: 0.540 
[m2] 463:32000 [train] erm-loss: 0.014, adv-loss: 1.959 [valid] acc: 0.546 
[m2] 478:33000 [train] erm-loss: 0.018, adv-loss: 2.200 [valid] acc: 0.542 
[m2] 492:34000 [train] erm-loss: 0.011, adv-loss: 2.025 [valid] acc: 0.542 
[m2] 507:35000 [train] erm-loss: 0.013, adv-loss: 2.016 [valid] acc: 0.546 
[m2] 521:36000 [train] erm-loss: 0.036, adv-loss: 2.352 [valid] acc: 0.542 
[m2] 536:37000 [train] erm-loss: 0.005, adv-loss: 1.732 [valid] acc: 0.548 
[m2] 550:38000 [train] erm-loss: 0.001, adv-loss: 1.907 [valid] acc: 0.536 
[m2] 565:39000 [train] erm-loss: 0.001, adv-loss: 1.754 [valid] acc: 0.546 
[m2] 579:40000 [train] erm-loss: 0.013, adv-loss: 1.728 [valid] acc: 0.544 
[m2] 594:41000 [train] erm-loss: 0.025, adv-loss: 1.619 [valid] acc: 0.544 
[m3] 0:0 [train] erm-loss: 4.524, adv-loss: 0.497 [valid] acc: 0.008 
[m3] 14:1000 [train] erm-loss: 0.187, adv-loss: 1.254 [valid] acc: 0.540 
[m3] 28:2000 [train] erm-loss: 0.049, adv-loss: 1.359 [valid] acc: 0.542 
[m3] 43:3000 [train] erm-loss: 0.039, adv-loss: 1.782 [valid] acc: 0.548 
[m3] 57:4000 [train] erm-loss: 0.070, adv-loss: 1.573 [valid] acc: 0.538 
[m3] 72:5000 [train] erm-loss: 0.034, adv-loss: 1.821 [valid] acc: 0.554 
[m3] 86:6000 [train] erm-loss: 0.035, adv-loss: 1.765 [valid] acc: 0.540 
[m3] 101:7000 [train] erm-loss: 0.005, adv-loss: 1.788 [valid] acc: 0.540 
[m3] 115:8000 [train] erm-loss: 0.005, adv-loss: 1.907 [valid] acc: 0.530 
[m3] 130:9000 [train] erm-loss: 0.021, adv-loss: 1.692 [valid] acc: 0.544 
[m3] 144:10000 [train] erm-loss: 0.028, adv-loss: 1.617 [valid] acc: 0.554 
[m3] 159:11000 [train] erm-loss: 0.009, adv-loss: 1.818 [valid] acc: 0.542 
[m3] 173:12000 [train] erm-loss: 0.009, adv-loss: 1.905 [valid] acc: 0.548 
[m3] 188:13000 [train] erm-loss: 0.013, adv-loss: 2.235 [valid] acc: 0.550 
[m3] 202:14000 [train] erm-loss: 0.021, adv-loss: 2.115 [valid] acc: 0.548 
[m3] 217:15000 [train] erm-loss: 0.017, adv-loss: 1.982 [valid] acc: 0.556 
[m3] 231:16000 [train] erm-loss: 0.025, adv-loss: 1.545 [valid] acc: 0.550 
[m3] 246:17000 [train] erm-loss: 0.002, adv-loss: 1.802 [valid] acc: 0.546 
[m3] 260:18000 [train] erm-loss: 0.046, adv-loss: 2.088 [valid] acc: 0.550 
[m3] 275:19000 [train] erm-loss: 0.010, adv-loss: 1.973 [valid] acc: 0.550 
[m3] 289:20000 [train] erm-loss: 0.018, adv-loss: 2.000 [valid] acc: 0.544 
[m3] 304:21000 [train] erm-loss: 0.005, adv-loss: 2.088 [valid] acc: 0.562 
[m3] 318:22000 [train] erm-loss: 0.017, adv-loss: 2.156 [valid] acc: 0.556 
[m3] 333:23000 [train] erm-loss: 0.011, adv-loss: 2.313 [valid] acc: 0.564 
[m3] 347:24000 [train] erm-loss: 0.010, adv-loss: 2.139 [valid] acc: 0.558 
[m3] 362:25000 [train] erm-loss: 0.020, adv-loss: 2.121 [valid] acc: 0.568 
[m3] 376:26000 [train] erm-loss: 0.008, adv-loss: 1.923 [valid] acc: 0.562 
[m3] 391:27000 [train] erm-loss: 0.025, adv-loss: 1.959 [valid] acc: 0.556 
[m3] 405:28000 [train] erm-loss: 0.008, adv-loss: 1.708 [valid] acc: 0.566 
[m3] 420:29000 [train] erm-loss: 0.015, adv-loss: 1.854 [valid] acc: 0.566 
[m3] 434:30000 [train] erm-loss: 0.006, adv-loss: 2.013 [valid] acc: 0.558 
[m3] 449:31000 [train] erm-loss: 0.019, adv-loss: 2.305 [valid] acc: 0.568 
[m3] 463:32000 [train] erm-loss: 0.019, adv-loss: 2.168 [valid] acc: 0.542 
[m3] 478:33000 [train] erm-loss: 0.021, adv-loss: 1.804 [valid] acc: 0.548 
[m3] 492:34000 [train] erm-loss: 0.024, adv-loss: 2.144 [valid] acc: 0.568 
[m3] 507:35000 [train] erm-loss: 0.001, adv-loss: 2.405 [valid] acc: 0.562 
[m3] 521:36000 [train] erm-loss: 0.013, adv-loss: 1.885 [valid] acc: 0.554 
[m3] 536:37000 [train] erm-loss: 0.001, adv-loss: 2.141 [valid] acc: 0.552 
[m3] 550:38000 [train] erm-loss: 0.028, adv-loss: 2.439 [valid] acc: 0.552 
[m3] 565:39000 [train] erm-loss: 0.009, adv-loss: 2.265 [valid] acc: 0.558 
[m3] 579:40000 [train] erm-loss: 0.019, adv-loss: 1.933 [valid] acc: 0.562 
[m3] 594:41000 [train] erm-loss: 0.010, adv-loss: 2.108 [valid] acc: 0.558 
[m4] 0:0 [train] erm-loss: 4.612, adv-loss: 0.360 [valid] acc: 0.008 
[m4] 14:1000 [train] erm-loss: 0.136, adv-loss: 1.231 [valid] acc: 0.520 
[m4] 28:2000 [train] erm-loss: 0.076, adv-loss: 1.554 [valid] acc: 0.526 
[m4] 43:3000 [train] erm-loss: 0.025, adv-loss: 1.520 [valid] acc: 0.536 
[m4] 57:4000 [train] erm-loss: 0.024, adv-loss: 1.861 [valid] acc: 0.528 
[m4] 72:5000 [train] erm-loss: 0.043, adv-loss: 1.770 [valid] acc: 0.542 
[m4] 86:6000 [train] erm-loss: 0.060, adv-loss: 1.969 [valid] acc: 0.530 
[m4] 101:7000 [train] erm-loss: 0.042, adv-loss: 1.806 [valid] acc: 0.524 
[m4] 115:8000 [train] erm-loss: 0.022, adv-loss: 1.948 [valid] acc: 0.528 
[m4] 130:9000 [train] erm-loss: 0.018, adv-loss: 1.768 [valid] acc: 0.528 
[m4] 144:10000 [train] erm-loss: 0.038, adv-loss: 2.181 [valid] acc: 0.536 
[m4] 159:11000 [train] erm-loss: 0.014, adv-loss: 2.310 [valid] acc: 0.544 
[m4] 173:12000 [train] erm-loss: 0.010, adv-loss: 1.927 [valid] acc: 0.542 
[m4] 188:13000 [train] erm-loss: 0.019, adv-loss: 1.764 [valid] acc: 0.540 
[m4] 202:14000 [train] erm-loss: 0.010, adv-loss: 2.361 [valid] acc: 0.532 
[m4] 217:15000 [train] erm-loss: 0.035, adv-loss: 2.089 [valid] acc: 0.538 
[m4] 231:16000 [train] erm-loss: 0.010, adv-loss: 2.050 [valid] acc: 0.532 
[m4] 246:17000 [train] erm-loss: 0.007, adv-loss: 2.321 [valid] acc: 0.530 
[m4] 260:18000 [train] erm-loss: 0.016, adv-loss: 2.053 [valid] acc: 0.524 
[m4] 275:19000 [train] erm-loss: 0.028, adv-loss: 2.210 [valid] acc: 0.524 
[m4] 289:20000 [train] erm-loss: 0.029, adv-loss: 2.141 [valid] acc: 0.542 
[m4] 304:21000 [train] erm-loss: 0.001, adv-loss: 2.311 [valid] acc: 0.546 
[m4] 318:22000 [train] erm-loss: 0.017, adv-loss: 1.690 [valid] acc: 0.534 
[m4] 333:23000 [train] erm-loss: 0.004, adv-loss: 1.939 [valid] acc: 0.536 
[m4] 347:24000 [train] erm-loss: 0.009, adv-loss: 2.189 [valid] acc: 0.536 
[m4] 362:25000 [train] erm-loss: 0.007, adv-loss: 2.238 [valid] acc: 0.548 
[m4] 376:26000 [train] erm-loss: 0.001, adv-loss: 2.564 [valid] acc: 0.542 
[m4] 391:27000 [train] erm-loss: 0.014, adv-loss: 1.808 [valid] acc: 0.530 
[m4] 405:28000 [train] erm-loss: 0.012, adv-loss: 1.969 [valid] acc: 0.538 
[m4] 420:29000 [train] erm-loss: 0.008, adv-loss: 1.876 [valid] acc: 0.540 
[m4] 434:30000 [train] erm-loss: 0.001, adv-loss: 2.011 [valid] acc: 0.538 
[m4] 449:31000 [train] erm-loss: 0.007, adv-loss: 2.236 [valid] acc: 0.542 
[m4] 463:32000 [train] erm-loss: 0.009, adv-loss: 1.704 [valid] acc: 0.536 
[m4] 478:33000 [train] erm-loss: 0.011, adv-loss: 2.132 [valid] acc: 0.532 
[m4] 492:34000 [train] erm-loss: 0.012, adv-loss: 2.002 [valid] acc: 0.538 
[m4] 507:35000 [train] erm-loss: 0.030, adv-loss: 1.962 [valid] acc: 0.542 
[m4] 521:36000 [train] erm-loss: 0.001, adv-loss: 2.117 [valid] acc: 0.538 
[m4] 536:37000 [train] erm-loss: 0.034, adv-loss: 2.520 [valid] acc: 0.540 
[m4] 550:38000 [train] erm-loss: 0.006, adv-loss: 1.671 [valid] acc: 0.544 
[m4] 565:39000 [train] erm-loss: 0.025, adv-loss: 2.128 [valid] acc: 0.530 
[m4] 579:40000 [train] erm-loss: 0.001, adv-loss: 2.142 [valid] acc: 0.534 
[m4] 594:41000 [train] erm-loss: 0.010, adv-loss: 1.992 [valid] acc: 0.542 
[m5] 0:0 [train] erm-loss: 4.466, adv-loss: 0.433 [valid] acc: 0.030 
[m5] 14:1000 [train] erm-loss: 0.158, adv-loss: 1.404 [valid] acc: 0.528 
[m5] 28:2000 [train] erm-loss: 0.058, adv-loss: 1.493 [valid] acc: 0.552 
[m5] 43:3000 [train] erm-loss: 0.026, adv-loss: 1.745 [valid] acc: 0.550 
[m5] 57:4000 [train] erm-loss: 0.055, adv-loss: 1.629 [valid] acc: 0.552 
[m5] 72:5000 [train] erm-loss: 0.020, adv-loss: 1.767 [valid] acc: 0.540 
[m5] 86:6000 [train] erm-loss: 0.006, adv-loss: 1.482 [valid] acc: 0.554 
[m5] 101:7000 [train] erm-loss: 0.031, adv-loss: 2.131 [valid] acc: 0.554 
[m5] 115:8000 [train] erm-loss: 0.007, adv-loss: 1.493 [valid] acc: 0.548 
[m5] 130:9000 [train] erm-loss: 0.016, adv-loss: 2.125 [valid] acc: 0.560 
[m5] 144:10000 [train] erm-loss: 0.011, adv-loss: 2.099 [valid] acc: 0.558 
[m5] 159:11000 [train] erm-loss: 0.009, adv-loss: 2.152 [valid] acc: 0.554 
[m5] 173:12000 [train] erm-loss: 0.008, adv-loss: 1.847 [valid] acc: 0.556 
[m5] 188:13000 [train] erm-loss: 0.034, adv-loss: 2.036 [valid] acc: 0.556 
[m5] 202:14000 [train] erm-loss: 0.012, adv-loss: 2.164 [valid] acc: 0.558 
[m5] 217:15000 [train] erm-loss: 0.052, adv-loss: 2.375 [valid] acc: 0.552 
[m5] 231:16000 [train] erm-loss: 0.016, adv-loss: 2.258 [valid] acc: 0.558 
[m5] 246:17000 [train] erm-loss: 0.045, adv-loss: 1.986 [valid] acc: 0.554 
[m5] 260:18000 [train] erm-loss: 0.039, adv-loss: 1.716 [valid] acc: 0.550 
[m5] 275:19000 [train] erm-loss: 0.012, adv-loss: 2.273 [valid] acc: 0.548 
[m5] 289:20000 [train] erm-loss: 0.012, adv-loss: 2.113 [valid] acc: 0.558 
[m5] 304:21000 [train] erm-loss: 0.002, adv-loss: 1.905 [valid] acc: 0.554 
[m5] 318:22000 [train] erm-loss: 0.015, adv-loss: 1.590 [valid] acc: 0.552 
[m5] 333:23000 [train] erm-loss: 0.007, adv-loss: 1.906 [valid] acc: 0.558 
[m5] 347:24000 [train] erm-loss: 0.017, adv-loss: 2.160 [valid] acc: 0.552 
[m5] 362:25000 [train] erm-loss: 0.009, adv-loss: 2.032 [valid] acc: 0.560 
[m5] 376:26000 [train] erm-loss: 0.011, adv-loss: 2.043 [valid] acc: 0.560 
[m5] 391:27000 [train] erm-loss: 0.001, adv-loss: 2.062 [valid] acc: 0.552 
[m5] 405:28000 [train] erm-loss: 0.015, adv-loss: 2.085 [valid] acc: 0.560 
[m5] 420:29000 [train] erm-loss: 0.014, adv-loss: 1.885 [valid] acc: 0.556 
[m5] 434:30000 [train] erm-loss: 0.006, adv-loss: 1.997 [valid] acc: 0.554 
[m5] 449:31000 [train] erm-loss: 0.010, adv-loss: 2.683 [valid] acc: 0.550 
[m5] 463:32000 [train] erm-loss: 0.020, adv-loss: 2.049 [valid] acc: 0.552 
[m5] 478:33000 [train] erm-loss: 0.002, adv-loss: 2.494 [valid] acc: 0.554 
[m5] 492:34000 [train] erm-loss: 0.006, adv-loss: 1.844 [valid] acc: 0.554 
[m5] 507:35000 [train] erm-loss: 0.015, adv-loss: 1.716 [valid] acc: 0.552 
[m5] 521:36000 [train] erm-loss: 0.036, adv-loss: 2.040 [valid] acc: 0.562 
[m5] 536:37000 [train] erm-loss: 0.011, adv-loss: 1.996 [valid] acc: 0.560 
[m5] 550:38000 [train] erm-loss: 0.036, adv-loss: 2.186 [valid] acc: 0.560 
[m5] 565:39000 [train] erm-loss: 0.018, adv-loss: 2.196 [valid] acc: 0.556 
[m5] 579:40000 [train] erm-loss: 0.011, adv-loss: 2.000 [valid] acc: 0.558 
[m5] 594:41000 [train] erm-loss: 0.005, adv-loss: 1.877 [valid] acc: 0.558 
[test m1] test-acc: 0.497
[test m2] test-acc: 0.512
[test m3] test-acc: 0.510
[test m4] test-acc: 0.499
[test m5] test-acc: 0.503
[test (last iterates ensemble)] test-acc: 0.544
[test ensemble given size] 0.497, 0.527, 0.539, 0.546, 0.544
