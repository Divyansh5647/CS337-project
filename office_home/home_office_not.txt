Loading dataset 'oh-65cls'
Train dataset length: 8804
Valid dataset length: 800
Test dataset length: 3557
Perturbations dataset length: 2427

Training 
{'ensemble_size': 5, 'batch_size_train': 128, 'batch_size_eval': 512, 'seed': 0, 'device': device(type='cuda', index=0), 'epochs': 600, 'lr': 0.001, 'l2_reg': 0.0001, 'scheduler': 'none', 'opt': 'sgd', 'eval_freq': 1000, 'ckpt_freq': 1, 'results_base_folder': './exps', 'no_diversity': True, 'dbat_loss_type': 'v1', 'perturb_type': 'ood_is_not_test', 'alpha': 0.0, 'model': 'resnet18', 'dataset': 'oh-65cls'}

[m1] 0:0 [train] erm-loss: 4.641, adv-loss: 0.000 [valid] acc: 0.025 
[m1] 14:1000 [train] erm-loss: 0.191, adv-loss: 0.000 [valid] acc: 0.511 
[m1] 28:2000 [train] erm-loss: 0.052, adv-loss: 0.000 [valid] acc: 0.517 
[m1] 43:3000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.517 
[m1] 57:4000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.531 
[m1] 72:5000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.530 
[m1] 86:6000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 101:7000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 115:8000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 130:9000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 144:10000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 159:11000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 173:12000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.531 
[m1] 188:13000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.537 
[m1] 202:14000 [train] erm-loss: 0.035, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 217:15000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.527 
[m1] 231:16000 [train] erm-loss: 0.032, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 246:17000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 260:18000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 275:19000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.539 
[m1] 289:20000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.522 
[m1] 304:21000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 318:22000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.539 
[m1] 333:23000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 347:24000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 362:25000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.540 
[m1] 376:26000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.542 
[m1] 391:27000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.540 
[m1] 405:28000 [train] erm-loss: 0.041, adv-loss: 0.000 [valid] acc: 0.540 
[m1] 420:29000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.539 
[m1] 434:30000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.529 
[m1] 449:31000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.540 
[m1] 463:32000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 478:33000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.541 
[m1] 492:34000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.542 
[m1] 507:35000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 521:36000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.544 
[m1] 536:37000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 550:38000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.542 
[m1] 565:39000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.539 
[m1] 579:40000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.544 
[m1] 594:41000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 0:0 [train] erm-loss: 4.422, adv-loss: 0.000 [valid] acc: 0.018 
[m2] 14:1000 [train] erm-loss: 0.181, adv-loss: 0.000 [valid] acc: 0.507 
[m2] 28:2000 [train] erm-loss: 0.052, adv-loss: 0.000 [valid] acc: 0.511 
[m2] 43:3000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.524 
[m2] 57:4000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.521 
[m2] 72:5000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.526 
[m2] 86:6000 [train] erm-loss: 0.040, adv-loss: 0.000 [valid] acc: 0.527 
[m2] 101:7000 [train] erm-loss: 0.026, adv-loss: 0.000 [valid] acc: 0.532 
[m2] 115:8000 [train] erm-loss: 0.039, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 130:9000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 144:10000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 159:11000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.541 
[m2] 173:12000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.531 
[m2] 188:13000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.529 
[m2] 202:14000 [train] erm-loss: 0.026, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 217:15000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.542 
[m2] 231:16000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.532 
[m2] 246:17000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.541 
[m2] 260:18000 [train] erm-loss: 0.042, adv-loss: 0.000 [valid] acc: 0.531 
[m2] 275:19000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.535 
[m2] 289:20000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.542 
[m2] 304:21000 [train] erm-loss: 0.032, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 318:22000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.544 
[m2] 333:23000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.535 
[m2] 347:24000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.539 
[m2] 362:25000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 376:26000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 391:27000 [train] erm-loss: 0.004, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 405:28000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 420:29000 [train] erm-loss: 0.004, adv-loss: 0.000 [valid] acc: 0.539 
[m2] 434:30000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.539 
[m2] 449:31000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 463:32000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.537 
[m2] 478:33000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 492:34000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 507:35000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 521:36000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.534 
[m2] 536:37000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.539 
[m2] 550:38000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.536 
[m2] 565:39000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.540 
[m2] 579:40000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.541 
[m2] 594:41000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 0:0 [train] erm-loss: 4.475, adv-loss: 0.000 [valid] acc: 0.010 
[m3] 14:1000 [train] erm-loss: 0.220, adv-loss: 0.000 [valid] acc: 0.510 
[m3] 28:2000 [train] erm-loss: 0.102, adv-loss: 0.000 [valid] acc: 0.512 
[m3] 43:3000 [train] erm-loss: 0.026, adv-loss: 0.000 [valid] acc: 0.512 
[m3] 57:4000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.521 
[m3] 72:5000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.521 
[m3] 86:6000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.520 
[m3] 101:7000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.519 
[m3] 115:8000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.526 
[m3] 130:9000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.525 
[m3] 144:10000 [train] erm-loss: 0.026, adv-loss: 0.000 [valid] acc: 0.527 
[m3] 159:11000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 173:12000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.524 
[m3] 188:13000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.531 
[m3] 202:14000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.525 
[m3] 217:15000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.531 
[m3] 231:16000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.529 
[m3] 246:17000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.532 
[m3] 260:18000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 275:19000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.530 
[m3] 289:20000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.531 
[m3] 304:21000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.524 
[m3] 318:22000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.527 
[m3] 333:23000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.531 
[m3] 347:24000 [train] erm-loss: 0.004, adv-loss: 0.000 [valid] acc: 0.532 
[m3] 362:25000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.532 
[m3] 376:26000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 391:27000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.530 
[m3] 405:28000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.537 
[m3] 420:29000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.532 
[m3] 434:30000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.535 
[m3] 449:31000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.526 
[m3] 463:32000 [train] erm-loss: 0.035, adv-loss: 0.000 [valid] acc: 0.522 
[m3] 478:33000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 492:34000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.536 
[m3] 507:35000 [train] erm-loss: 0.004, adv-loss: 0.000 [valid] acc: 0.529 
[m3] 521:36000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.534 
[m3] 536:37000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.539 
[m3] 550:38000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.530 
[m3] 565:39000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.530 
[m3] 579:40000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.535 
[m3] 594:41000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.527 
[m4] 0:0 [train] erm-loss: 4.580, adv-loss: 0.000 [valid] acc: 0.015 
[m4] 14:1000 [train] erm-loss: 0.166, adv-loss: 0.000 [valid] acc: 0.505 
[m4] 28:2000 [train] erm-loss: 0.053, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 43:3000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.510 
[m4] 57:4000 [train] erm-loss: 0.048, adv-loss: 0.000 [valid] acc: 0.512 
[m4] 72:5000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.519 
[m4] 86:6000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.526 
[m4] 101:7000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.519 
[m4] 115:8000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.522 
[m4] 130:9000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 144:10000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.524 
[m4] 159:11000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.510 
[m4] 173:12000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 188:13000 [train] erm-loss: 0.040, adv-loss: 0.000 [valid] acc: 0.514 
[m4] 202:14000 [train] erm-loss: 0.030, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 217:15000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.521 
[m4] 231:16000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.519 
[m4] 246:17000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 260:18000 [train] erm-loss: 0.026, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 275:19000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.511 
[m4] 289:20000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 304:21000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 318:22000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 333:23000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.514 
[m4] 347:24000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 362:25000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.512 
[m4] 376:26000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 391:27000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.522 
[m4] 405:28000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.517 
[m4] 420:29000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.516 
[m4] 434:30000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.514 
[m4] 449:31000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.511 
[m4] 463:32000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.512 
[m4] 478:33000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.512 
[m4] 492:34000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 507:35000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 521:36000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 536:37000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.514 
[m4] 550:38000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.514 
[m4] 565:39000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.515 
[m4] 579:40000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.511 
[m4] 594:41000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.512 
[m5] 0:0 [train] erm-loss: 4.554, adv-loss: 0.000 [valid] acc: 0.026 
[m5] 14:1000 [train] erm-loss: 0.202, adv-loss: 0.000 [valid] acc: 0.521 
[m5] 28:2000 [train] erm-loss: 0.038, adv-loss: 0.000 [valid] acc: 0.530 
[m5] 43:3000 [train] erm-loss: 0.043, adv-loss: 0.000 [valid] acc: 0.532 
[m5] 57:4000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.530 
[m5] 72:5000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.534 
[m5] 86:6000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.531 
[m5] 101:7000 [train] erm-loss: 0.030, adv-loss: 0.000 [valid] acc: 0.531 
[m5] 115:8000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.536 
[m5] 130:9000 [train] erm-loss: 0.008, adv-loss: 0.000 [valid] acc: 0.537 
[m5] 144:10000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.527 
[m5] 159:11000 [train] erm-loss: 0.031, adv-loss: 0.000 [valid] acc: 0.531 
[m5] 173:12000 [train] erm-loss: 0.049, adv-loss: 0.000 [valid] acc: 0.532 
[m5] 188:13000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.539 
[m5] 202:14000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.534 
[m5] 217:15000 [train] erm-loss: 0.002, adv-loss: 0.000 [valid] acc: 0.532 
[m5] 231:16000 [train] erm-loss: 0.010, adv-loss: 0.000 [valid] acc: 0.534 
[m5] 246:17000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.526 
[m5] 260:18000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.540 
[m5] 275:19000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.522 
[m5] 289:20000 [train] erm-loss: 0.047, adv-loss: 0.000 [valid] acc: 0.526 
[m5] 304:21000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.532 
[m5] 318:22000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.529 
[m5] 333:23000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.527 
[m5] 347:24000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.536 
[m5] 362:25000 [train] erm-loss: 0.027, adv-loss: 0.000 [valid] acc: 0.539 
[m5] 376:26000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.537 
[m5] 391:27000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.532 
[m5] 405:28000 [train] erm-loss: 0.029, adv-loss: 0.000 [valid] acc: 0.526 
[m5] 420:29000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.534 
[m5] 434:30000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.534 
[m5] 449:31000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.532 
[m5] 463:32000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.525 
[m5] 478:33000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.527 
[m5] 492:34000 [train] erm-loss: 0.022, adv-loss: 0.000 [valid] acc: 0.529 
[m5] 507:35000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.531 
[m5] 521:36000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.527 
[m5] 536:37000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.529 
[m5] 550:38000 [train] erm-loss: 0.020, adv-loss: 0.000 [valid] acc: 0.529 
[m5] 565:39000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.530 
[m5] 579:40000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.526 
[m5] 594:41000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.529 
[test m1] test-acc: 0.513
[test m2] test-acc: 0.509
[test m3] test-acc: 0.509
[test m4] test-acc: 0.503
[test m5] test-acc: 0.529
[test (last iterates ensemble)] test-acc: 0.555
[test ensemble given size] 0.513, 0.534, 0.540, 0.545, 0.555
Loading dataset 'oh-65cls'
Train dataset length: 8804
Valid dataset length: 800
Test dataset length: 3557
Perturbations dataset length: 2427

Training 
{'ensemble_size': 5, 'batch_size_train': 128, 'batch_size_eval': 512, 'seed': 0, 'device': device(type='cuda', index=0), 'epochs': 600, 'lr': 0.001, 'l2_reg': 0.0001, 'scheduler': 'none', 'opt': 'sgd', 'eval_freq': 1000, 'ckpt_freq': 1, 'results_base_folder': './exps', 'no_diversity': False, 'dbat_loss_type': 'v1', 'perturb_type': 'ood_is_not_test', 'alpha': 1e-05, 'model': 'resnet18', 'dataset': 'oh-65cls'}

[m1] 0:0 [train] erm-loss: 4.641, adv-loss: 0.000 [valid] acc: 0.025 
[m1] 14:1000 [train] erm-loss: 0.193, adv-loss: 0.000 [valid] acc: 0.511 
[m1] 28:2000 [train] erm-loss: 0.050, adv-loss: 0.000 [valid] acc: 0.515 
[m1] 43:3000 [train] erm-loss: 0.034, adv-loss: 0.000 [valid] acc: 0.519 
[m1] 57:4000 [train] erm-loss: 0.011, adv-loss: 0.000 [valid] acc: 0.529 
[m1] 72:5000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.527 
[m1] 86:6000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 101:7000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 115:8000 [train] erm-loss: 0.016, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 130:9000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.525 
[m1] 144:10000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.530 
[m1] 159:11000 [train] erm-loss: 0.009, adv-loss: 0.000 [valid] acc: 0.525 
[m1] 173:12000 [train] erm-loss: 0.028, adv-loss: 0.000 [valid] acc: 0.530 
[m1] 188:13000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.540 
[m1] 202:14000 [train] erm-loss: 0.036, adv-loss: 0.000 [valid] acc: 0.527 
[m1] 217:15000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.520 
[m1] 231:16000 [train] erm-loss: 0.032, adv-loss: 0.000 [valid] acc: 0.530 
[m1] 246:17000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.530 
[m1] 260:18000 [train] erm-loss: 0.014, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 275:19000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.537 
[m1] 289:20000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.524 
[m1] 304:21000 [train] erm-loss: 0.007, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 318:22000 [train] erm-loss: 0.023, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 333:23000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.526 
[m1] 347:24000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.531 
[m1] 362:25000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.537 
[m1] 376:26000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 391:27000 [train] erm-loss: 0.015, adv-loss: 0.000 [valid] acc: 0.532 
[m1] 405:28000 [train] erm-loss: 0.041, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 420:29000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.535 
[m1] 434:30000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.529 
[m1] 449:31000 [train] erm-loss: 0.006, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 463:32000 [train] erm-loss: 0.012, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 478:33000 [train] erm-loss: 0.001, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 492:34000 [train] erm-loss: 0.017, adv-loss: 0.000 [valid] acc: 0.544 
[m1] 507:35000 [train] erm-loss: 0.025, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 521:36000 [train] erm-loss: 0.013, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 536:37000 [train] erm-loss: 0.021, adv-loss: 0.000 [valid] acc: 0.536 
[m1] 550:38000 [train] erm-loss: 0.024, adv-loss: 0.000 [valid] acc: 0.539 
[m1] 565:39000 [train] erm-loss: 0.018, adv-loss: 0.000 [valid] acc: 0.534 
[m1] 579:40000 [train] erm-loss: 0.019, adv-loss: 0.000 [valid] acc: 0.542 
[m1] 594:41000 [train] erm-loss: 0.005, adv-loss: 0.000 [valid] acc: 0.537 
[m2] 0:0 [train] erm-loss: 4.422, adv-loss: 0.548 [valid] acc: 0.016 
[m2] 14:1000 [train] erm-loss: 0.181, adv-loss: 0.875 [valid] acc: 0.514 
[m2] 28:2000 [train] erm-loss: 0.052, adv-loss: 1.059 [valid] acc: 0.524 
[m2] 43:3000 [train] erm-loss: 0.018, adv-loss: 1.117 [valid] acc: 0.532 
[m2] 57:4000 [train] erm-loss: 0.021, adv-loss: 1.296 [valid] acc: 0.531 
[m2] 72:5000 [train] erm-loss: 0.028, adv-loss: 0.943 [valid] acc: 0.534 
[m2] 86:6000 [train] erm-loss: 0.039, adv-loss: 1.180 [valid] acc: 0.531 
[m2] 101:7000 [train] erm-loss: 0.027, adv-loss: 1.271 [valid] acc: 0.532 
[m2] 115:8000 [train] erm-loss: 0.038, adv-loss: 0.896 [valid] acc: 0.530 
[m2] 130:9000 [train] erm-loss: 0.021, adv-loss: 1.316 [valid] acc: 0.529 
[m2] 144:10000 [train] erm-loss: 0.015, adv-loss: 1.221 [valid] acc: 0.532 
[m2] 159:11000 [train] erm-loss: 0.020, adv-loss: 1.150 [valid] acc: 0.529 
[m2] 173:12000 [train] erm-loss: 0.003, adv-loss: 1.343 [valid] acc: 0.534 
[m2] 188:13000 [train] erm-loss: 0.012, adv-loss: 1.111 [valid] acc: 0.530 
[m2] 202:14000 [train] erm-loss: 0.027, adv-loss: 1.224 [valid] acc: 0.540 
[m2] 217:15000 [train] erm-loss: 0.008, adv-loss: 1.251 [valid] acc: 0.534 
[m2] 231:16000 [train] erm-loss: 0.014, adv-loss: 1.141 [valid] acc: 0.534 
[m2] 246:17000 [train] erm-loss: 0.020, adv-loss: 1.380 [valid] acc: 0.530 
[m2] 260:18000 [train] erm-loss: 0.042, adv-loss: 1.308 [valid] acc: 0.535 
[m2] 275:19000 [train] erm-loss: 0.011, adv-loss: 1.430 [valid] acc: 0.535 
[m2] 289:20000 [train] erm-loss: 0.018, adv-loss: 1.323 [valid] acc: 0.534 
[m2] 304:21000 [train] erm-loss: 0.032, adv-loss: 1.184 [valid] acc: 0.531 
[m2] 318:22000 [train] erm-loss: 0.008, adv-loss: 1.170 [valid] acc: 0.535 
[m2] 333:23000 [train] erm-loss: 0.016, adv-loss: 1.306 [valid] acc: 0.532 
[m2] 347:24000 [train] erm-loss: 0.005, adv-loss: 1.313 [valid] acc: 0.540 
[m2] 362:25000 [train] erm-loss: 0.017, adv-loss: 1.241 [valid] acc: 0.541 
[m2] 376:26000 [train] erm-loss: 0.001, adv-loss: 1.255 [valid] acc: 0.544 
[m2] 391:27000 [train] erm-loss: 0.004, adv-loss: 1.285 [valid] acc: 0.534 
[m2] 405:28000 [train] erm-loss: 0.026, adv-loss: 1.394 [valid] acc: 0.537 
[m2] 420:29000 [train] erm-loss: 0.005, adv-loss: 1.465 [valid] acc: 0.541 
[m2] 434:30000 [train] erm-loss: 0.012, adv-loss: 1.279 [valid] acc: 0.535 
[m2] 449:31000 [train] erm-loss: 0.012, adv-loss: 1.437 [valid] acc: 0.541 
[m2] 463:32000 [train] erm-loss: 0.001, adv-loss: 1.418 [valid] acc: 0.536 
[m2] 478:33000 [train] erm-loss: 0.001, adv-loss: 1.408 [valid] acc: 0.534 
[m2] 492:34000 [train] erm-loss: 0.006, adv-loss: 1.392 [valid] acc: 0.532 
[m2] 507:35000 [train] erm-loss: 0.001, adv-loss: 1.332 [valid] acc: 0.534 
[m2] 521:36000 [train] erm-loss: 0.011, adv-loss: 1.431 [valid] acc: 0.548 
[m2] 536:37000 [train] erm-loss: 0.011, adv-loss: 1.345 [valid] acc: 0.536 
[m2] 550:38000 [train] erm-loss: 0.009, adv-loss: 1.365 [valid] acc: 0.540 
[m2] 565:39000 [train] erm-loss: 0.021, adv-loss: 1.359 [valid] acc: 0.537 
[m2] 579:40000 [train] erm-loss: 0.022, adv-loss: 1.155 [valid] acc: 0.544 
[m2] 594:41000 [train] erm-loss: 0.023, adv-loss: 1.065 [valid] acc: 0.537 
[m3] 0:0 [train] erm-loss: 4.475, adv-loss: 0.604 [valid] acc: 0.007 
[m3] 14:1000 [train] erm-loss: 0.217, adv-loss: 0.910 [valid] acc: 0.527 
[m3] 28:2000 [train] erm-loss: 0.106, adv-loss: 0.988 [valid] acc: 0.524 
[m3] 43:3000 [train] erm-loss: 0.024, adv-loss: 1.210 [valid] acc: 0.520 
[m3] 57:4000 [train] erm-loss: 0.027, adv-loss: 1.244 [valid] acc: 0.534 
[m3] 72:5000 [train] erm-loss: 0.007, adv-loss: 1.285 [valid] acc: 0.527 
[m3] 86:6000 [train] erm-loss: 0.016, adv-loss: 1.160 [valid] acc: 0.526 
[m3] 101:7000 [train] erm-loss: 0.020, adv-loss: 1.260 [valid] acc: 0.540 
[m3] 115:8000 [train] erm-loss: 0.012, adv-loss: 1.181 [valid] acc: 0.530 
[m3] 130:9000 [train] erm-loss: 0.009, adv-loss: 1.178 [valid] acc: 0.531 
[m3] 144:10000 [train] erm-loss: 0.026, adv-loss: 1.363 [valid] acc: 0.529 
[m3] 159:11000 [train] erm-loss: 0.017, adv-loss: 1.121 [valid] acc: 0.529 
[m3] 173:12000 [train] erm-loss: 0.028, adv-loss: 1.314 [valid] acc: 0.529 
[m3] 188:13000 [train] erm-loss: 0.012, adv-loss: 1.211 [valid] acc: 0.531 
[m3] 202:14000 [train] erm-loss: 0.026, adv-loss: 1.306 [valid] acc: 0.530 
[m3] 217:15000 [train] erm-loss: 0.014, adv-loss: 1.378 [valid] acc: 0.529 
[m3] 231:16000 [train] erm-loss: 0.006, adv-loss: 1.255 [valid] acc: 0.530 
[m3] 246:17000 [train] erm-loss: 0.013, adv-loss: 1.245 [valid] acc: 0.529 
[m3] 260:18000 [train] erm-loss: 0.007, adv-loss: 1.132 [valid] acc: 0.535 
[m3] 275:19000 [train] erm-loss: 0.007, adv-loss: 1.227 [valid] acc: 0.531 
[m3] 289:20000 [train] erm-loss: 0.017, adv-loss: 1.236 [valid] acc: 0.532 
[m3] 304:21000 [train] erm-loss: 0.023, adv-loss: 1.226 [valid] acc: 0.534 
[m3] 318:22000 [train] erm-loss: 0.017, adv-loss: 1.040 [valid] acc: 0.534 
[m3] 333:23000 [train] erm-loss: 0.013, adv-loss: 1.382 [valid] acc: 0.542 
[m3] 347:24000 [train] erm-loss: 0.004, adv-loss: 1.555 [valid] acc: 0.537 
[m3] 362:25000 [train] erm-loss: 0.009, adv-loss: 1.243 [valid] acc: 0.535 
[m3] 376:26000 [train] erm-loss: 0.008, adv-loss: 1.438 [valid] acc: 0.536 
[m3] 391:27000 [train] erm-loss: 0.020, adv-loss: 1.321 [valid] acc: 0.537 
[m3] 405:28000 [train] erm-loss: 0.008, adv-loss: 1.358 [valid] acc: 0.532 
[m3] 420:29000 [train] erm-loss: 0.010, adv-loss: 1.247 [valid] acc: 0.531 
[m3] 434:30000 [train] erm-loss: 0.025, adv-loss: 1.544 [valid] acc: 0.540 
[m3] 449:31000 [train] erm-loss: 0.015, adv-loss: 1.413 [valid] acc: 0.540 
[m3] 463:32000 [train] erm-loss: 0.036, adv-loss: 1.284 [valid] acc: 0.536 
[m3] 478:33000 [train] erm-loss: 0.011, adv-loss: 1.385 [valid] acc: 0.541 
[m3] 492:34000 [train] erm-loss: 0.001, adv-loss: 1.245 [valid] acc: 0.548 
[m3] 507:35000 [train] erm-loss: 0.004, adv-loss: 1.192 [valid] acc: 0.540 
[m3] 521:36000 [train] erm-loss: 0.001, adv-loss: 1.151 [valid] acc: 0.534 
[m3] 536:37000 [train] erm-loss: 0.023, adv-loss: 1.269 [valid] acc: 0.541 
[m3] 550:38000 [train] erm-loss: 0.019, adv-loss: 1.150 [valid] acc: 0.540 
[m3] 565:39000 [train] erm-loss: 0.007, adv-loss: 1.387 [valid] acc: 0.541 
[m3] 579:40000 [train] erm-loss: 0.012, adv-loss: 1.415 [valid] acc: 0.541 
[m3] 594:41000 [train] erm-loss: 0.007, adv-loss: 1.466 [valid] acc: 0.545 
[m4] 0:0 [train] erm-loss: 4.580, adv-loss: 0.606 [valid] acc: 0.016 
[m4] 14:1000 [train] erm-loss: 0.167, adv-loss: 0.987 [valid] acc: 0.502 
[m4] 28:2000 [train] erm-loss: 0.052, adv-loss: 1.136 [valid] acc: 0.512 
[m4] 43:3000 [train] erm-loss: 0.020, adv-loss: 1.052 [valid] acc: 0.522 
[m4] 57:4000 [train] erm-loss: 0.047, adv-loss: 1.318 [valid] acc: 0.517 
[m4] 72:5000 [train] erm-loss: 0.006, adv-loss: 1.300 [valid] acc: 0.529 
[m4] 86:6000 [train] erm-loss: 0.025, adv-loss: 1.405 [valid] acc: 0.527 
[m4] 101:7000 [train] erm-loss: 0.025, adv-loss: 1.077 [valid] acc: 0.520 
[m4] 115:8000 [train] erm-loss: 0.017, adv-loss: 1.163 [valid] acc: 0.526 
[m4] 130:9000 [train] erm-loss: 0.021, adv-loss: 1.390 [valid] acc: 0.534 
[m4] 144:10000 [train] erm-loss: 0.021, adv-loss: 1.259 [valid] acc: 0.536 
[m4] 159:11000 [train] erm-loss: 0.016, adv-loss: 1.247 [valid] acc: 0.535 
[m4] 173:12000 [train] erm-loss: 0.008, adv-loss: 1.205 [valid] acc: 0.537 
[m4] 188:13000 [train] erm-loss: 0.039, adv-loss: 1.064 [valid] acc: 0.525 
[m4] 202:14000 [train] erm-loss: 0.029, adv-loss: 1.189 [valid] acc: 0.529 
[m4] 217:15000 [train] erm-loss: 0.002, adv-loss: 1.289 [valid] acc: 0.532 
[m4] 231:16000 [train] erm-loss: 0.008, adv-loss: 1.228 [valid] acc: 0.537 
[m4] 246:17000 [train] erm-loss: 0.023, adv-loss: 1.084 [valid] acc: 0.532 
[m4] 260:18000 [train] erm-loss: 0.025, adv-loss: 1.415 [valid] acc: 0.537 
[m4] 275:19000 [train] erm-loss: 0.007, adv-loss: 1.256 [valid] acc: 0.532 
[m4] 289:20000 [train] erm-loss: 0.026, adv-loss: 1.238 [valid] acc: 0.537 
[m4] 304:21000 [train] erm-loss: 0.001, adv-loss: 1.275 [valid] acc: 0.529 
[m4] 318:22000 [train] erm-loss: 0.006, adv-loss: 1.261 [valid] acc: 0.537 
[m4] 333:23000 [train] erm-loss: 0.001, adv-loss: 1.422 [valid] acc: 0.539 
[m4] 347:24000 [train] erm-loss: 0.010, adv-loss: 1.335 [valid] acc: 0.539 
[m4] 362:25000 [train] erm-loss: 0.007, adv-loss: 1.470 [valid] acc: 0.532 
[m4] 376:26000 [train] erm-loss: 0.006, adv-loss: 1.475 [valid] acc: 0.534 
[m4] 391:27000 [train] erm-loss: 0.011, adv-loss: 1.407 [valid] acc: 0.541 
[m4] 405:28000 [train] erm-loss: 0.006, adv-loss: 1.180 [valid] acc: 0.527 
[m4] 420:29000 [train] erm-loss: 0.021, adv-loss: 1.125 [valid] acc: 0.532 
[m4] 434:30000 [train] erm-loss: 0.016, adv-loss: 1.616 [valid] acc: 0.535 
[m4] 449:31000 [train] erm-loss: 0.014, adv-loss: 1.560 [valid] acc: 0.530 
[m4] 463:32000 [train] erm-loss: 0.008, adv-loss: 1.193 [valid] acc: 0.536 
[m4] 478:33000 [train] erm-loss: 0.026, adv-loss: 1.457 [valid] acc: 0.535 
[m4] 492:34000 [train] erm-loss: 0.009, adv-loss: 1.268 [valid] acc: 0.537 
[m4] 507:35000 [train] erm-loss: 0.012, adv-loss: 1.312 [valid] acc: 0.530 
[m4] 521:36000 [train] erm-loss: 0.005, adv-loss: 1.289 [valid] acc: 0.527 
[m4] 536:37000 [train] erm-loss: 0.015, adv-loss: 1.263 [valid] acc: 0.530 
[m4] 550:38000 [train] erm-loss: 0.014, adv-loss: 1.201 [valid] acc: 0.534 
[m4] 565:39000 [train] erm-loss: 0.011, adv-loss: 1.270 [valid] acc: 0.537 
[m4] 579:40000 [train] erm-loss: 0.012, adv-loss: 1.419 [valid] acc: 0.531 
[m4] 594:41000 [train] erm-loss: 0.008, adv-loss: 1.386 [valid] acc: 0.534 
[m5] 0:0 [train] erm-loss: 4.554, adv-loss: 0.616 [valid] acc: 0.026 
[m5] 14:1000 [train] erm-loss: 0.202, adv-loss: 1.032 [valid] acc: 0.534 
[m5] 28:2000 [train] erm-loss: 0.038, adv-loss: 1.383 [valid] acc: 0.540 
[m5] 43:3000 [train] erm-loss: 0.045, adv-loss: 1.134 [valid] acc: 0.555 
[m5] 57:4000 [train] erm-loss: 0.015, adv-loss: 1.156 [valid] acc: 0.545 
[m5] 72:5000 [train] erm-loss: 0.029, adv-loss: 1.184 [valid] acc: 0.550 
[m5] 86:6000 [train] erm-loss: 0.027, adv-loss: 1.212 [valid] acc: 0.548 
[m5] 101:7000 [train] erm-loss: 0.029, adv-loss: 1.174 [valid] acc: 0.551 
[m5] 115:8000 [train] erm-loss: 0.014, adv-loss: 1.257 [valid] acc: 0.555 
[m5] 130:9000 [train] erm-loss: 0.008, adv-loss: 1.162 [valid] acc: 0.554 
[m5] 144:10000 [train] erm-loss: 0.008, adv-loss: 1.114 [valid] acc: 0.551 
[m5] 159:11000 [train] erm-loss: 0.031, adv-loss: 1.157 [valid] acc: 0.559 
[m5] 173:12000 [train] erm-loss: 0.048, adv-loss: 1.187 [valid] acc: 0.553 
[m5] 188:13000 [train] erm-loss: 0.011, adv-loss: 1.128 [valid] acc: 0.558 
[m5] 202:14000 [train] erm-loss: 0.007, adv-loss: 1.339 [valid] acc: 0.555 
[m5] 217:15000 [train] erm-loss: 0.002, adv-loss: 1.234 [valid] acc: 0.546 
[m5] 231:16000 [train] erm-loss: 0.011, adv-loss: 1.450 [valid] acc: 0.554 
[m5] 246:17000 [train] erm-loss: 0.016, adv-loss: 1.344 [valid] acc: 0.546 
[m5] 260:18000 [train] erm-loss: 0.016, adv-loss: 1.503 [valid] acc: 0.560 
[m5] 275:19000 [train] erm-loss: 0.022, adv-loss: 1.361 [valid] acc: 0.553 
[m5] 289:20000 [train] erm-loss: 0.046, adv-loss: 1.398 [valid] acc: 0.554 
[m5] 304:21000 [train] erm-loss: 0.006, adv-loss: 1.420 [valid] acc: 0.559 
[m5] 318:22000 [train] erm-loss: 0.022, adv-loss: 1.318 [valid] acc: 0.549 
[m5] 333:23000 [train] erm-loss: 0.028, adv-loss: 1.299 [valid] acc: 0.556 
[m5] 347:24000 [train] erm-loss: 0.020, adv-loss: 1.338 [valid] acc: 0.560 
[m5] 362:25000 [train] erm-loss: 0.027, adv-loss: 1.203 [valid] acc: 0.555 
[m5] 376:26000 [train] erm-loss: 0.009, adv-loss: 1.489 [valid] acc: 0.556 
[m5] 391:27000 [train] erm-loss: 0.012, adv-loss: 1.186 [valid] acc: 0.549 
[m5] 405:28000 [train] erm-loss: 0.028, adv-loss: 1.416 [valid] acc: 0.556 
[m5] 420:29000 [train] erm-loss: 0.001, adv-loss: 1.155 [valid] acc: 0.558 
[m5] 434:30000 [train] erm-loss: 0.001, adv-loss: 1.356 [valid] acc: 0.551 
[m5] 449:31000 [train] erm-loss: 0.018, adv-loss: 1.411 [valid] acc: 0.558 
[m5] 463:32000 [train] erm-loss: 0.013, adv-loss: 1.210 [valid] acc: 0.550 
[m5] 478:33000 [train] erm-loss: 0.024, adv-loss: 1.277 [valid] acc: 0.550 
[m5] 492:34000 [train] erm-loss: 0.022, adv-loss: 1.453 [valid] acc: 0.559 
[m5] 507:35000 [train] erm-loss: 0.023, adv-loss: 1.554 [valid] acc: 0.549 
[m5] 521:36000 [train] erm-loss: 0.028, adv-loss: 1.507 [valid] acc: 0.546 
[m5] 536:37000 [train] erm-loss: 0.016, adv-loss: 1.295 [valid] acc: 0.553 
[m5] 550:38000 [train] erm-loss: 0.021, adv-loss: 1.285 [valid] acc: 0.551 
[m5] 565:39000 [train] erm-loss: 0.012, adv-loss: 1.236 [valid] acc: 0.540 
[m5] 579:40000 [train] erm-loss: 0.019, adv-loss: 1.662 [valid] acc: 0.555 
[m5] 594:41000 [train] erm-loss: 0.011, adv-loss: 1.396 [valid] acc: 0.542 
[test m1] test-acc: 0.511
[test m2] test-acc: 0.511
[test m3] test-acc: 0.509
[test m4] test-acc: 0.514
[test m5] test-acc: 0.527
[test (last iterates ensemble)] test-acc: 0.556
[test ensemble given size] 0.511, 0.534, 0.543, 0.550, 0.556
